{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Digital Futures](https://github.com/digital-futures-academy/DataScienceMasterResources/blob/main/Resources/datascience-notebook-header.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Project Environment\n",
    "\n",
    "Ultimately, the Python code written here will be extracted to scripts for execution in an automated pipeline.  To facilitate this, there is a need to set up a project environment that will allow for the execution of the code in a controlled and reproducible environment.\n",
    "\n",
    "In the initial stages of the activities, the packages needed are `requests` and `pytest`.  The `requests` package is used to make HTTP requests to the API, while `pytest` is used for testing the code we also need *BeautifulSoup* (package name `beautifulsoup4`.  In later activities, you may need to install additional packages.  To do this, add the packages to the `pip install` command below and re-run the cell.\n",
    "\n",
    "> **Remember:** The goal is to create a set of code cells that can be extracted to separate scripts for execution in an automated pipeline.  Therefore, the code should be kept in 3 distinct cells:\n",
    "> \n",
    "> - **Shell Commands**:  Used to set up the project environment\n",
    "> \n",
    "> - **Python Tests**: Used to test the Python production scripts both now and as part of the automated pipeline\n",
    "> \n",
    "> - **Python Production Code**: The Python code that will be extracted to a script to execute during the pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup Scripts\n",
    "\n",
    "If you are running this notebook after cloning and have not set up your environment to run shell commands, you will need to run the following commands in your terminal to set up the environment.\n",
    "\n",
    "> **NOTE:**  These commands need to be executed in the terminal.  \n",
    ">\n",
    "> Open a terminal at the root of your project before executing these commands\n",
    "> \n",
    "> Until your environment is set up, Jupyter Notebooks will not be able to run **shell** scripts.\n",
    "\n",
    "```sh\n",
    "# Create a virtual environment (add the command below)\n",
    "python3 -m venv .venv # Note: This command could also be python -m venv .venv # python3 and python are a symlink to the python version installed on your system\n",
    "\n",
    "# Activate the virtual environment \n",
    "source .venv/bin/activate\n",
    "\n",
    "# Install required package to execute shell commands from Jupyter Notebook\n",
    "pip install ipykernel               ## OR \n",
    "pip install -r requirements.txt     ## IF there is already a requirements.txt file CONTAINING ipykenrnel in the project\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install the necessary packages\n",
    "!pip install requests pytest beautifulsoup4\n",
    "\n",
    "# Create a requirements.txt file\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** \n",
    "> The `!` at the beginning of the lines is a special character in Jupyter Notebooks that allows you to run shell commands from the notebook.  \n",
    "> These will need to be removed from any commands that are to be exported to a `.sh` shell script file for the pipeline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Tests\n",
    "\n",
    "Develop any tests for functions in separate cells below.  The first has been provided for you as an example, add others as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Constants\n",
    "TEST_URL = 'https://www.testsite.com'\n",
    "TEST_HTML = '<html><body><h1>Hello, World!</h1></body></html>'\n",
    "JSON_CONTENT = '{\"key\": \"value\"}'\n",
    "HTML_PARSER = 'html.parser'\n",
    "\n",
    "# Constants for expected results for requests\n",
    "SUCCESS_STATUS = \"success\"\n",
    "ERROR_STATUS = \"error\"\n",
    "ERROR_NOT_HTML = \"The response is not HTML\"\n",
    "ERROR_REQUEST_FAILED = \"Request failed for URL\"\n",
    "ERROR_UNEXPECTED = \"Unexpected error for URL\"\n",
    "\n",
    "# Constant Test Data and HTML for Extract Book Categories\n",
    "\n",
    "# List of categories for testing category extraction\n",
    "TEST_CATEGORIES_WITH_LINKS = [\n",
    "    {'Category 1': {'link': f\"{TEST_URL}/category1.html\"}},\n",
    "    {'Category 2': {'link': f\"{TEST_URL}/category2.html\"}},\n",
    "    {'Category No Link Attr': {}},\n",
    "    {'Category Link None': {'link': None}},\n",
    "    {'Category Invalid Link': {'link': 'invalid-url'}},\n",
    "]\n",
    "\n",
    "# Test List of book data\n",
    "TEST_BOOK_DATA = [\n",
    "    {'title': 'Book 1', 'price': 10.99},\n",
    "    {'title': 'Book 2', 'price': 15.99},\n",
    "    {'title': 'Book 3', 'price': 9.99},\n",
    "    {'title': 'Invalidly Priced', 'price': 'Invalid Price'},\n",
    "    {'title': 'None Price', 'price': None},\n",
    "    {'title': None, 'price': 20.99},\n",
    "    {'title': 'Additional Data', 'price': 10.99, 'extra': 'data'},\n",
    "    {'title': None, 'price': None},\n",
    "    {'title': 'Very long title truncated in display', 'price': 30.99}\n",
    "]\n",
    "\n",
    "# HTML for category link extraction\n",
    "CATEGORY_HTML_VALID = '''\n",
    "<ul class=\"nav nav-list\">\n",
    "    <ul>\n",
    "        <li><a href=\"category1.html\">Category 1</a></li>\n",
    "        <li><a href=\"category2.html\">Category 2</a></li>\n",
    "    </ul>\n",
    "</ul>\n",
    "'''\n",
    "\n",
    "CATEGORY_HTML_WITHOUT_NAV_LIST = '<ul></ul>'\n",
    "\n",
    "CATEGORY_HTML_INVALID = f'''\n",
    "    <ul class=\"nav nav-list\">\n",
    "        <ul>\n",
    "            <li>\n",
    "                <a \n",
    "                    href=\"category1.html\"\n",
    "                >{next(iter(TEST_CATEGORIES_WITH_LINKS[0]))}\n",
    "'''\n",
    "# next(iter()) extracts the category name of the dictionary supplied\n",
    "\n",
    "CATEGORY_HTML_NO_HREF = f'''\n",
    "    <ul class=\"nav nav-list\">\n",
    "        <ul><li><a>{next(iter(TEST_CATEGORIES_WITH_LINKS[3]))}</a></li></ul>\n",
    "    </ul>\n",
    "'''\n",
    "\n",
    "\n",
    "CATEGORY_HTML_INVALID = f'''\n",
    "    <ul class=\"nav nav-list\">\n",
    "        <ul>\n",
    "            <li>\n",
    "                <a \n",
    "                    href=\"category1.html\"\n",
    "                >{next(iter(TEST_CATEGORIES_WITH_LINKS[0]))}\n",
    "'''\n",
    "# Test HTML for testing category extraction from nav list\n",
    "NAV_HTML_WITH_CLASS = '<ul class=\"nav nav-list\"><li>Item</li></ul>'\n",
    "NAV_HTML_WITHOUT_CLASS = '<ul><li>Item</li></ul>'\n",
    "NAV_HTML_WITHOUT_UL_TAG = '<div class=\"content\"><p>No ul here</p></div>'\n",
    "NAV_HTML_WITH_DIFFERENT_CLASS = '''\n",
    "<ul class=\"different-class\"><li>Item</li></ul>\n",
    "'''\n",
    "NAV_HTML_INVALID = '<ul class=\"nav nav-list\"><li>Item'\n",
    "\n",
    "# Test HTML for Number of Books\n",
    "BOOK_NUMBER_HTML_VALID = '''\n",
    "    <form class=\"form-horizontal\">\n",
    "        <strong>10</strong> books found\n",
    "    </form>\n",
    "'''\n",
    "BOOK_NUMBER_HTML_WITHOUT_NUMBER = '''\n",
    "<form class=\"form-horizontal\">No books found</form>\n",
    "'''\n",
    "BOOK_NUMBER_HTML_INVALID = '<form class=\"form-horizontal\"><strong>10'\n",
    "BOOK_NUMBER_HTML_NO_BOOKS_FOUND = '''\n",
    "    <form class=\"form-horizontal\">\n",
    "        <strong>0</strong> books found\n",
    "    </form>\n",
    "'''\n",
    "BOOK_NUMBER_HTML_NO_BOOKS_FOUND_TEXT = '''\n",
    "<form class=\"form-horizontal\">No books found</form>\n",
    "'''\n",
    "BOOK_NUMBER_HTML_NON_NUMERIC_BOOK_NUMBER = '''\n",
    "    <form class=\"form-horizontal\">\n",
    "        <strong>Not a number</strong> books found\n",
    "    </form>\n",
    "'''\n",
    "BOOK_NUMBER_HTML_NO_FORM_HORIZONTAL = '<form><strong>10</strong></form>'\n",
    "\n",
    "# Book data HTML for testing\n",
    "BOOK_DATA_HTML_VALID = f'''\n",
    "<html>\n",
    "    <body>\n",
    "        <article class=\"product_pod\">\n",
    "            <h3>\n",
    "                <a title=\"{TEST_BOOK_DATA[0]['title']}\">\n",
    "                    {TEST_BOOK_DATA[0]['title']}\n",
    "                </a>\n",
    "            </h3>\n",
    "            <p class=\"price_color\">Â£{TEST_BOOK_DATA[0]['price']}9</p>\n",
    "        </article>\n",
    "        <article class=\"product_pod\">\n",
    "            <h3>\n",
    "                <a title=\"{TEST_BOOK_DATA[2]['title']}\">\n",
    "                    {TEST_BOOK_DATA[2]['title']}\n",
    "                </a>\n",
    "            </h3>\n",
    "            <p class=\"price_color\">Â£{TEST_BOOK_DATA[2]['price']}9</p>\n",
    "        </article>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "BOOK_DATA_HTML_INVALID = f'''\n",
    "<html>\n",
    "    <body>\n",
    "        <article class=\"product_pod\">\n",
    "            <h3>{TEST_BOOK_DATA[3]['title']}</h3>\n",
    "            <p class=\"price_color\">{TEST_BOOK_DATA[3]['price']}</p>\n",
    "        </article>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "TITLE_LINK_NO_PRICE = f'<a title=\"{TEST_BOOK_DATA[4]['title']}\">{TEST_BOOK_DATA[4]['title']}</a>' # noqa E501\n",
    "\n",
    "BOOK_DATA_HTML_MISSING_PRICE = f'''\n",
    "    <html>\n",
    "        <body>\n",
    "            <article class=\"product_pod\">\n",
    "                <h3>\n",
    "                    {TITLE_LINK_NO_PRICE}\n",
    "            </article>\n",
    "        </body>\n",
    "    </html>\n",
    "'''\n",
    "\n",
    "SINGLE_BOOK_PRICE_HTML_NONE = '<p class=\"price_color\"></p>'\n",
    "\n",
    "SINGLE_BOOK_TITLE_HTML_NO_ATTR = f'''\n",
    "    <h3>{TEST_BOOK_DATA[0]['title']}</h3>\n",
    "'''\n",
    "\n",
    "TITLE_LINK_VALID = f'<a title=\"{TEST_BOOK_DATA[0]['title']}\">{TEST_BOOK_DATA[0]['title']}</a>' # noqa E501\n",
    "\n",
    "SINGLE_BOOK_TITLE_HTML_VALID = f'''\n",
    "    <h3>{TITLE_LINK_VALID}</h3>\n",
    "'''\n",
    "SINGLE_BOOK_PRICE_HTML_VALID = f'''\n",
    "    <p class=\"price_color\">Â£{TEST_BOOK_DATA[0]['price']}</p>\n",
    "'''\n",
    "\n",
    "SINGLE_BOOK_PRICE_HTML_INVALID = f'''\n",
    "    <p class=\"price_color\">{TEST_BOOK_DATA[3]['price']}</p>\n",
    "'''\n",
    "\n",
    "TRUNCATED_TITLE_LINK = f'<a title=\"{TEST_BOOK_DATA[8]['title']}\">{TEST_BOOK_DATA[8]['title'][:10]}...</a>'  # noqa E501\n",
    "\n",
    "SINGLE_BOOK_TITLE_HTML_TRUNCATED = f'''\n",
    "    <h3>{TRUNCATED_TITLE_LINK}</h3>\n",
    "'''\n",
    "\n",
    "SINGLE_BOOK_TITLE_TRUN_PRICE_HTML_VALID = f'''\n",
    "    <p class=\"price_color\">Â£{TEST_BOOK_DATA[8]['price']}</p>\n",
    "'''\n",
    "\n",
    "SINGLE_BOOK_PRICE_HTML_NONE = '<p class=\"price_color\"></p>'\n",
    "\n",
    "SINGLE_BOOK_TITLE_HTML_NO_ATTR = f'''\n",
    "    <h3>{TEST_BOOK_DATA[0]['title']}</h3>\n",
    "'''\n",
    "\n",
    "BOOK_DATA_HTML_NO_TITLE_ATTR = f'''\n",
    "    <article class=\"product_pod\">\n",
    "        {SINGLE_BOOK_TITLE_HTML_NO_ATTR}\n",
    "        {SINGLE_BOOK_PRICE_HTML_VALID}\n",
    "    </article>\n",
    "'''\n",
    "\n",
    "BOOK_DATA_HTML_TRUNCATED_TITLE = f'''\n",
    "    <article class=\"product_pod\">\n",
    "        {SINGLE_BOOK_TITLE_HTML_TRUNCATED}\n",
    "        {SINGLE_BOOK_TITLE_TRUN_PRICE_HTML_VALID}\n",
    "    </article>\n",
    "'''\n",
    "\n",
    "# Pagination HTML data for testing\n",
    "\n",
    "PAGINATION_VALID = '<li class=\"current\">Page 1 of 4</li>'\n",
    "PAGINATION_INVALID = '<li class=\"current\">Page one of four</li>'\n",
    "PAGINATION_EDGE_400 = '<li class=\"current\">Page 1 of 400</li>'\n",
    "PAGINATION_EDGE_40 = '<li class=\"current\">Page 1 of 40</li>'\n",
    "PAGINATION_EDGE_4 = '<li class=\"current\">Page 1 of 4</li>'\n",
    "\n",
    "BOOK_DATA_HTML_MISSING_TITLE = f'''\n",
    "    <html>\n",
    "        <body>\n",
    "            <article class=\"product_pod\">\n",
    "                <p class=\"price_color\">Â£{TEST_BOOK_DATA[5]['price']}</p>\n",
    "            </article>\n",
    "        </body>\n",
    "    </html>\n",
    "'''\n",
    "\n",
    "BOOK_DATA_HTML_MIXED = f'''\n",
    "    <html>\n",
    "        <body>\n",
    "            <article class=\"product_pod\">\n",
    "                {SINGLE_BOOK_TITLE_HTML_VALID}\n",
    "                {SINGLE_BOOK_PRICE_HTML_VALID}\n",
    "            </article>\n",
    "            <article class=\"product_pod\">\n",
    "                <h3>\n",
    "                    <a title=\"{TEST_BOOK_DATA[4]['title']}\">\n",
    "                        {TEST_BOOK_DATA[4]['title']}\n",
    "                    </a>\n",
    "                </h3>\n",
    "                <p class=\"price_color\">{TEST_BOOK_DATA[4]['price']}</p>\n",
    "            </article>\n",
    "            <article class=\"product_pod\">\n",
    "                <h3>\n",
    "                    <a title=\"{TEST_BOOK_DATA[5]['title']}\">\n",
    "                        {TEST_BOOK_DATA[5]['title']}\n",
    "                    </a>\n",
    "                </h3>\n",
    "                <p class=\"price_color\">Â£{TEST_BOOK_DATA[5]['price']}</p>\n",
    "            </article>\n",
    "            <article class=\"product_pod\">\n",
    "                <h3>\n",
    "                    <a title=\"{TEST_BOOK_DATA[7]['title']}\">\n",
    "                        {TEST_BOOK_DATA[7]['title']}\n",
    "                    </a>\n",
    "                </h3>\n",
    "                <p class=\"price_color\">{TEST_BOOK_DATA[7]['price']}</p>\n",
    "            </article>\n",
    "        </body>\n",
    "    </html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `request_to_scrape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test request_to_scrape\n",
    "import pytest\n",
    "from unittest.mock import patch\n",
    "from requests.exceptions import Timeout, RequestException\n",
    "\n",
    "def test_request_to_scrape_makes_correct_request():\n",
    "    \"\"\"\n",
    "    Test that the function makes a request to the correct URL.\n",
    "    \"\"\"\n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.return_value.status_code = 200\n",
    "        request_to_scrape(TEST_URL)\n",
    "        mock_get.assert_called_once_with(TEST_URL, timeout=10)\n",
    "\n",
    "def test_request_to_scrape_returns_html_for_200():\n",
    "    \"\"\"\n",
    "    Test that the function returns the HTML content\n",
    "    when the request is successful (status code 200).\n",
    "    \"\"\"\n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.return_value.status_code = 200\n",
    "        mock_get.return_value.headers = {'Content-Type': 'text/html'}\n",
    "        mock_get.return_value.text = TEST_HTML\n",
    "        result = request_to_scrape(TEST_URL)\n",
    "        assert result == {\n",
    "            \"status\": SUCCESS_STATUS,\n",
    "            \"data\": TEST_HTML\n",
    "        }\n",
    "\n",
    "def test_request_to_scrape_handles_non_200():\n",
    "    \"\"\"\n",
    "    Test that the function returns an error message\n",
    "    when the response status code is not 200.\n",
    "    \"\"\"\n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.return_value.status_code = 404\n",
    "        result = request_to_scrape(TEST_URL)\n",
    "        assert result == {\n",
    "            \"status\": ERROR_STATUS,\n",
    "            \"error\": ERROR_NOT_HTML\n",
    "        }\n",
    "\n",
    "def test_request_to_scrape_non_html_content():\n",
    "    \"\"\"\n",
    "    Test that the function returns an error message\n",
    "    when the response type is not HTML.\n",
    "    \"\"\"\n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.return_value.status_code = 200\n",
    "        mock_get.return_value.headers = {'Content-Type': 'application/json'}\n",
    "        mock_get.return_value.text = JSON_CONTENT\n",
    "        result = request_to_scrape(TEST_URL)\n",
    "        assert result == {\n",
    "            \"status\": ERROR_STATUS,\n",
    "            \"error\": ERROR_NOT_HTML\n",
    "        }\n",
    "\n",
    "@pytest.mark.parametrize(\"exception, error_message\", [\n",
    "    (\n",
    "        Exception(\"An error occurred\"),\n",
    "        \"An error occurred - Unexpected error for URL\"\n",
    "    ),\n",
    "    (\n",
    "        Timeout(\"The request timed out\"),\n",
    "        \"The request timed out - Request failed for URL\"\n",
    "    ),\n",
    "    (\n",
    "        RequestException(\"Invalid URL\"),\n",
    "        \"Invalid URL - Request failed for URL\"\n",
    "    )\n",
    "])\n",
    "def test_request_to_scrape_handles_exceptions(exception, error_message):\n",
    "    \"\"\"\n",
    "    Test that the function returns an error message \n",
    "    when an exception occurs during the request.\n",
    "    \"\"\"\n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.side_effect = exception\n",
    "        result = request_to_scrape(TEST_URL)\n",
    "        assert result == {\n",
    "            \"status\": ERROR_STATUS,\n",
    "            \"error\": error_message\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_book_categories`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `extract_book_categories`\n",
    "\n",
    "def test_extract_book_categories_with_valid_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_book_categories` correctly parses valid HTML input.\n",
    "    \"\"\"  # noqa E501\n",
    "    categories = extract_book_categories(\n",
    "        CATEGORY_HTML_VALID, \n",
    "        TEST_URL\n",
    "    )\n",
    "    assert categories == { \n",
    "        **TEST_CATEGORIES_WITH_LINKS[0],\n",
    "        **TEST_CATEGORIES_WITH_LINKS[1]\n",
    "    }\n",
    "\n",
    "def test_extract_book_categories_with_html_without_nav_list():\n",
    "    \"\"\"\n",
    "    Test that `extract_book_categories` returns an empty dictionary when the HTML content does not contain a navigation list.\n",
    "    \"\"\"  # noqa E501\n",
    "    categories = extract_book_categories(\n",
    "        CATEGORY_HTML_WITHOUT_NAV_LIST,\n",
    "        TEST_URL\n",
    "    )\n",
    "    assert categories == {}\n",
    "\n",
    "def test_extract_book_categories_with_empty_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_book_categories` returns an empty dictionary when provided with an empty HTML string.\n",
    "    \"\"\"  # noqa E501\n",
    "    categories = extract_book_categories(\n",
    "        TEST_HTML,\n",
    "        TEST_URL\n",
    "    )\n",
    "    assert categories == {}\n",
    "\n",
    "def test_extract_book_categories_with_invalid_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_book_categories` can correctly parse and extract book categories from invalid HTML input.\n",
    "    \"\"\"  # noqa E501\n",
    "    categories = extract_book_categories(\n",
    "        CATEGORY_HTML_INVALID,\n",
    "        TEST_URL\n",
    "    )\n",
    "    assert categories == TEST_CATEGORIES_WITH_LINKS[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_element`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extract_element\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "@pytest.fixture\n",
    "def soup_with_class():\n",
    "    return BeautifulSoup(NAV_HTML_WITH_CLASS, HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def soup_without_class():\n",
    "    return BeautifulSoup(NAV_HTML_WITHOUT_CLASS, HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def soup_without_tag():\n",
    "    return BeautifulSoup(NAV_HTML_WITHOUT_UL_TAG, HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def soup_with_different_class():\n",
    "    return BeautifulSoup(NAV_HTML_WITH_DIFFERENT_CLASS, HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def empty_soup():\n",
    "    return BeautifulSoup('', HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def invalid_soup():\n",
    "    return BeautifulSoup(NAV_HTML_INVALID, HTML_PARSER)\n",
    "\n",
    "def test_extract_element_with_valid_html_with_class(\n",
    "    soup_with_class\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` correctly extracts an element with a specific class.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(soup_with_class, 'ul', 'nav nav-list')\n",
    "    assert element is not None\n",
    "    assert element['class'] == ['nav', 'nav-list']\n",
    "\n",
    "def test_extract_element_with_valid_html_without_class(\n",
    "    soup_without_class\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` correctly extracts an element without a class.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(soup_without_class, 'ul')\n",
    "    assert element is not None\n",
    "    assert element.name == 'ul'\n",
    "\n",
    "def test_extract_element_with_html_without_tag(\n",
    "    soup_without_tag\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` returns None when the specified tag is not present.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(soup_without_tag, 'ul')\n",
    "    assert element is None\n",
    "\n",
    "def test_extract_element_with_html_with_different_class(\n",
    "    soup_with_different_class\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` returns None when the class does not match.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(soup_with_different_class, 'ul', 'nav nav-list')\n",
    "    assert element is None\n",
    "\n",
    "def test_extract_element_with_empty_html(\n",
    "    empty_soup\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` returns None when provided with empty HTML content.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(empty_soup, 'ul')\n",
    "    assert element is None\n",
    "\n",
    "def test_extract_element_with_invalid_html(\n",
    "    invalid_soup\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` can handle and correctly parse invalid HTML input.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(invalid_soup, 'ul', 'nav nav-list')\n",
    "    assert element is not None\n",
    "    assert element['class'] == ['nav', 'nav-list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_categories_and_links`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extract_categories_and_links\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def test_extract_categories_and_links_with_valid_html_with_multiple_categories():  # noqa E501\n",
    "    \"\"\"\n",
    "    Test that `extract_categories_and_links` correctly extracts categories and their links from valid HTML input.\n",
    "    \"\"\"  # noqa E501\n",
    "    expected_output = {\n",
    "        **TEST_CATEGORIES_WITH_LINKS[0],\n",
    "        **TEST_CATEGORIES_WITH_LINKS[1]\n",
    "    }\n",
    "    soup = BeautifulSoup(CATEGORY_HTML_VALID, HTML_PARSER)\n",
    "    category_list = soup.find('ul')\n",
    "    categories = extract_categories_and_links(category_list, TEST_URL)\n",
    "    assert categories == expected_output\n",
    "\n",
    "def test_extract_categories_and_links_with_none():\n",
    "    \"\"\"\n",
    "    Test that `extract_categories_and_links` returns an empty dictionary when input is None.\n",
    "    \"\"\"  # noqa E501\n",
    "    categories = extract_categories_and_links(None, TEST_URL)\n",
    "    assert categories == {}\n",
    "\n",
    "def test_extract_categories_and_links_with_empty_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_categories_and_links` returns an empty dictionary when HTML is empty.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(TEST_HTML, HTML_PARSER)\n",
    "    category_list = soup.find('ul')\n",
    "    categories = extract_categories_and_links(category_list, TEST_URL)\n",
    "    assert categories == {}\n",
    "\n",
    "def test_extract_categories_and_links_with_html_without_a_tags():\n",
    "    \"\"\"\n",
    "    Test that `extract_categories_and_links` returns an empty dictionary when there are no `a` tags in the HTML.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(CATEGORY_HTML_WITHOUT_NAV_LIST, HTML_PARSER)\n",
    "    category_list = soup.find('ul')\n",
    "    categories = extract_categories_and_links(category_list, TEST_URL)\n",
    "    assert categories == {}\n",
    "\n",
    "def test_extract_categories_and_links_with_a_tags_without_href():\n",
    "    \"\"\"\n",
    "    Test that `extract_categories_and_links` handles `a` tags without `href` attributes gracefully.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(CATEGORY_HTML_NO_HREF, HTML_PARSER)\n",
    "    category_list = soup.find('ul')\n",
    "    categories = extract_categories_and_links(category_list, TEST_URL)\n",
    "    assert categories == TEST_CATEGORIES_WITH_LINKS[3]\n",
    "\n",
    "def test_extract_categories_and_links_with_invalid_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_categories_and_links` handles invalid HTML gracefully.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(CATEGORY_HTML_INVALID, HTML_PARSER)\n",
    "    category_list = soup.find('ul')\n",
    "    categories = extract_categories_and_links(category_list, TEST_URL)\n",
    "    assert categories == TEST_CATEGORIES_WITH_LINKS[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_book_categories`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extract_book_categories\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def test_extract_book_categories_with_valid_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_book_categories` correctly parses valid HTML input.\n",
    "    \"\"\"  # noqa E501\n",
    "    categories = extract_book_categories(\n",
    "        CATEGORY_HTML_VALID, \n",
    "        TEST_URL\n",
    "    )\n",
    "    assert categories == { \n",
    "        **TEST_CATEGORIES_WITH_LINKS[0],\n",
    "        **TEST_CATEGORIES_WITH_LINKS[1]\n",
    "    }\n",
    "\n",
    "def test_extract_book_categories_with_html_without_nav_list():\n",
    "    \"\"\"\n",
    "    Test that `extract_book_categories` returns an empty dictionary when the HTML content does not contain a navigation list.\n",
    "    \"\"\"  # noqa E501\n",
    "    categories = extract_book_categories(\n",
    "        CATEGORY_HTML_WITHOUT_NAV_LIST,\n",
    "        TEST_URL\n",
    "    )\n",
    "    assert categories == {}\n",
    "\n",
    "def test_extract_book_categories_with_empty_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_book_categories` returns an empty dictionary when provided with an empty HTML string.\n",
    "    \"\"\"  # noqa E501\n",
    "    categories = extract_book_categories(\n",
    "        TEST_HTML,\n",
    "        TEST_URL\n",
    "    )\n",
    "    assert categories == {}\n",
    "\n",
    "def test_extract_book_categories_with_invalid_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_book_categories` can correctly parse and extract book categories from invalid HTML input.\n",
    "    \"\"\"  # noqa E501\n",
    "    categories = extract_book_categories(\n",
    "        CATEGORY_HTML_INVALID,\n",
    "        TEST_URL\n",
    "    )\n",
    "    assert categories == TEST_CATEGORIES_WITH_LINKS[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_category_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `extract_category_data`\n",
    "import pytest\n",
    "from unittest.mock import patch\n",
    "\n",
    "@pytest.fixture\n",
    "def test_category_data():\n",
    "    return {\n",
    "        'category': 'Category 1',\n",
    "        'link': f\"{TEST_URL}/category1.html\",\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def expected_category_data_valid():\n",
    "    return {\n",
    "        'category': 'Category 1',\n",
    "        'link': f\"{TEST_URL}/category1.html\",\n",
    "        'number_of_books': 50\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def expected_category_data_invalid():\n",
    "    return {\n",
    "        'category': 'Category 1',\n",
    "        'link': f\"{TEST_URL}/category1.html\",\n",
    "        'number_of_books': 0\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def expected_category_data_with_books():\n",
    "    return {\n",
    "        'category': 'Category 1',\n",
    "        'link': f\"{TEST_URL}/category1.html\",\n",
    "        'number_of_books': 50,\n",
    "        'books': TEST_BOOK_DATA\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def expected_category_data_invalid_with_books():\n",
    "    return {\n",
    "        'category': 'Category 1',\n",
    "        'link': f\"{TEST_URL}/category1.html\",\n",
    "        'number_of_books': 0,\n",
    "        'books': TEST_BOOK_DATA\n",
    "    }\n",
    "\n",
    "def test_extract_category_data_valid_book_number(\n",
    "    test_category_data,\n",
    "    expected_category_data_valid\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` correctly adds the number of books in a category\n",
    "    when `extract_number_in_category` returns a valid integer.\n",
    "    \"\"\"  # noqa E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={\n",
    "                'status': 'success',\n",
    "                'data': BOOK_NUMBER_HTML_VALID\n",
    "            }\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value=50\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(test_category_data)\n",
    "        assert category_data == expected_category_data_valid\n",
    "\n",
    "def test_extract_category_data_invalid_book_number(\n",
    "    test_category_data,\n",
    "    expected_category_data_invalid\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` returns 0 books in category when `extract_number_in_category`\n",
    "    returns an invalid integer value.\n",
    "    \"\"\"  # noqa E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={\n",
    "                'status': 'success',\n",
    "                'data': BOOK_NUMBER_HTML_INVALID\n",
    "            }\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value='Not a number'\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(test_category_data)\n",
    "        assert category_data == expected_category_data_invalid\n",
    "\n",
    "def test_extract_category_data_request_to_scrape_failure(\n",
    "    test_category_data\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` handles request_to_scrape failure gracefully.\n",
    "    \"\"\"  # noqa E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={'status': 'error', 'data': ''}\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value=0\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(test_category_data)\n",
    "        assert category_data['number_of_books'] == 0\n",
    "\n",
    "def test_extract_category_data_empty_html_response(\n",
    "    test_category_data\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` handles empty HTML response gracefully.\n",
    "    \"\"\"  # noqa E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={'status': 'success', 'data': ''}\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value=0\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(test_category_data)\n",
    "        assert category_data['number_of_books'] == 0\n",
    "\n",
    "def test_extract_category_data_test_no_books_found(\n",
    "    test_category_data\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` returns 0 books when no books are found.\n",
    "    \"\"\"  # noqa E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={\n",
    "                'status': 'success',\n",
    "                'data': BOOK_NUMBER_HTML_NO_BOOKS_FOUND\n",
    "            }\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value=0\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(test_category_data)\n",
    "        assert category_data['number_of_books'] == 0\n",
    "\n",
    "\"\"\"\n",
    "TESTS FOR WHEN `get_book_data` is True\n",
    "\"\"\"\n",
    "\n",
    "def test_extract_category_data_valid_book_number_with_books(\n",
    "    test_category_data,\n",
    "    expected_category_data_with_books\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` correctly adds the number of books in a category\n",
    "    and extracts book data when `get_book_data` is True and `extract_number_in_category`\n",
    "    returns a valid integer.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={\n",
    "                'status': 'success',\n",
    "                'data': BOOK_NUMBER_HTML_VALID\n",
    "            }\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value=50\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data',\n",
    "            return_value=TEST_BOOK_DATA\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(\n",
    "            test_category_data,\n",
    "            get_book_data=True\n",
    "        )\n",
    "        assert category_data == expected_category_data_with_books\n",
    "\n",
    "def test_extract_category_data_invalid_book_number_with_books(\n",
    "    test_category_data,\n",
    "    expected_category_data_invalid_with_books\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` returns 0 books in category and extracts book data\n",
    "    when `get_book_data` is True and `extract_number_in_category` returns an invalid integer value.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={\n",
    "                'status': 'success',\n",
    "                'data': BOOK_NUMBER_HTML_INVALID\n",
    "            }\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value='Not a number'\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data',\n",
    "            return_value=TEST_BOOK_DATA\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(\n",
    "            test_category_data,\n",
    "            get_book_data=True\n",
    "        )\n",
    "        assert category_data == expected_category_data_invalid_with_books\n",
    "\n",
    "def test_extract_category_data_request_to_scrape_failure_with_books(\n",
    "    test_category_data\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` handles request_to_scrape failure gracefully\n",
    "    and still extracts book data when `get_book_data` is True.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={'status': 'error', 'data': ''}\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value=0\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data',\n",
    "            return_value=TEST_BOOK_DATA\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(\n",
    "            test_category_data,\n",
    "            get_book_data=True\n",
    "        )\n",
    "        assert category_data['number_of_books'] == 0\n",
    "        assert category_data['books'] == TEST_BOOK_DATA\n",
    "\n",
    "def test_extract_category_data_empty_html_response_with_books(\n",
    "    test_category_data\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` handles empty HTML response gracefully\n",
    "    and still extracts book data when `get_book_data` is True.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={'status': 'success', 'data': ''}\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value=0\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data',\n",
    "            return_value=TEST_BOOK_DATA\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(\n",
    "            test_category_data,\n",
    "            get_book_data=True\n",
    "        )\n",
    "        assert category_data['number_of_books'] == 0\n",
    "        assert category_data['books'] == TEST_BOOK_DATA\n",
    "\n",
    "def test_extract_category_data_no_books_found_with_books(\n",
    "    test_category_data\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_category_data` returns 0 books when no books are found\n",
    "    and still extracts book data when `get_book_data` is True.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value={\n",
    "                'status': 'success',\n",
    "                'data': BOOK_NUMBER_HTML_NO_BOOKS_FOUND\n",
    "            }\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_number_in_category',\n",
    "            return_value=0\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data',\n",
    "            return_value=TEST_BOOK_DATA\n",
    "        )\n",
    "    ):\n",
    "        category_data = extract_category_data(\n",
    "            test_category_data,\n",
    "            get_book_data=True\n",
    "        )\n",
    "        assert category_data['number_of_books'] == 0\n",
    "        assert category_data['books'] == TEST_BOOK_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_number_in_category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `extract_number_in_category`\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def test_extract_number_in_category_with_valid_html_with_number():\n",
    "    \"\"\"\n",
    "    Test that `extract_number_in_category` correctly extracts the number of books from valid HTML.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(BOOK_NUMBER_HTML_VALID, HTML_PARSER)\n",
    "    number = extract_number_in_category(soup)\n",
    "    assert number == 10\n",
    "\n",
    "def test_extract_number_html_without_number():\n",
    "    \"\"\"\n",
    "    Test that `extract_number_in_category` returns 0 when the number of books is not found.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(BOOK_NUMBER_HTML_NO_BOOKS_FOUND_TEXT, HTML_PARSER)\n",
    "    number = extract_number_in_category(soup)\n",
    "    assert number == 0\n",
    "\n",
    "def test_extract_number_empty_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_number_in_category` returns 0 when provided with empty HTML.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(TEST_HTML, HTML_PARSER)\n",
    "    number = extract_number_in_category(soup)\n",
    "    assert number == 0\n",
    "\n",
    "def test_extract_number_invalid_html():\n",
    "    \"\"\"\n",
    "    Test that `extract_number_in_category` correctly extracts the number of books from invalid HTML.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(BOOK_NUMBER_HTML_VALID, HTML_PARSER)\n",
    "    number = extract_number_in_category(soup)\n",
    "    assert number == 10\n",
    "\n",
    "def test_extract_number_html_with_no_books_found():\n",
    "    \"\"\"\n",
    "    Test that `extract_number_in_category` returns 0 when the HTML indicates no books found.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(BOOK_NUMBER_HTML_NO_BOOKS_FOUND, HTML_PARSER)\n",
    "    number = extract_number_in_category(soup)\n",
    "    assert number == 0\n",
    "\n",
    "def test_extract_number_html_with_no_books_found_text():\n",
    "    \"\"\"\n",
    "    Test that `extract_number_in_category` returns 0 when the HTML indicates no books found.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(BOOK_NUMBER_HTML_NO_BOOKS_FOUND_TEXT, HTML_PARSER)\n",
    "    number = extract_number_in_category(soup)\n",
    "    assert number == 0\n",
    "\n",
    "def test_extract_number_html_with_non_numeric_number_of_books():\n",
    "    \"\"\"\n",
    "    Test that `extract_number_in_category` returns 0 when the HTML contains a non-numeric value.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(BOOK_NUMBER_HTML_NON_NUMERIC_BOOK_NUMBER, HTML_PARSER)\n",
    "    number = extract_number_in_category(soup)\n",
    "    assert number == 0\n",
    "\n",
    "def test_extract_number_no_form_horizontal_class():\n",
    "    \"\"\"\n",
    "    Test that `extract_number_in_category` returns 0 when the HTML does not contain the 'form-horizontal' class.\n",
    "    \"\"\"  # noqa E501\n",
    "    soup = BeautifulSoup(BOOK_NUMBER_HTML_NO_FORM_HORIZONTAL, HTML_PARSER)\n",
    "    number = extract_number_in_category(soup)\n",
    "    assert number == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_all_category_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `extract_all_category_data`\n",
    "import pytest\n",
    "from unittest.mock import patch\n",
    "\n",
    "@pytest.fixture\n",
    "def valid_categories():\n",
    "    return {\n",
    "        **TEST_CATEGORIES_WITH_LINKS[0],\n",
    "        **TEST_CATEGORIES_WITH_LINKS[1]\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def empty_categories():\n",
    "    return {}\n",
    "\n",
    "@pytest.fixture\n",
    "def single_category():\n",
    "    return {\n",
    "        **TEST_CATEGORIES_WITH_LINKS[0]\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def invalid_category_link():\n",
    "    return {\n",
    "        **TEST_CATEGORIES_WITH_LINKS[4]\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def category_with_missing_link():\n",
    "    return {\n",
    "        **TEST_CATEGORIES_WITH_LINKS[2]\n",
    "    }\n",
    "\n",
    "# @pytest.fixture\n",
    "# def category_with_additional_data():\n",
    "#     return {\n",
    "#         **TEST_CATEGORIES_WITH_LINKS[6]\n",
    "#     }\n",
    "\n",
    "def test_extract_all_category_data_makes_right_extract_category_data_call(\n",
    "    valid_categories\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_all_category_data` calls `extract_category_data` with correct arguments.\n",
    "\n",
    "    Asserts:\n",
    "        - The function calls `extract_category_data` with the correct category link arguments.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch('__main__.extract_category_data') as mock_extract_category_data\n",
    "    ):\n",
    "        extract_all_category_data(valid_categories)\n",
    "        assert mock_extract_category_data.call_count == 2\n",
    "        mock_extract_category_data.assert_any_call(\n",
    "            {'link': f'{TEST_URL}/category1.html'}, False\n",
    "        )\n",
    "        mock_extract_category_data.assert_any_call(\n",
    "            {'link': f'{TEST_URL}/category2.html'}, False\n",
    "        )\n",
    "\n",
    "def test_extract_all_category_data_empty_categories(\n",
    "    empty_categories\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_all_category_data` handles empty categories dictionary.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch('__main__.extract_category_data') as mock_extract_category_data\n",
    "    ):\n",
    "        result = extract_all_category_data(empty_categories)\n",
    "        assert result == {}\n",
    "        assert mock_extract_category_data.call_count == 0\n",
    "\n",
    "def test_extract_all_category_data_single_category(\n",
    "    single_category\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_all_category_data` handles single category.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch('__main__.extract_category_data') as mock_extract_category_data\n",
    "    ):\n",
    "        extract_all_category_data(single_category)\n",
    "        assert mock_extract_category_data.call_count == 1\n",
    "        mock_extract_category_data.assert_any_call(\n",
    "            {'link': f'{TEST_URL}/category1.html'}, False\n",
    "        )\n",
    "\n",
    "def test_extract_all_category_data_invalid_category_link(\n",
    "    invalid_category_link\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_all_category_data` handles invalid category link.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch('__main__.extract_category_data') as mock_extract_category_data\n",
    "    ):\n",
    "        extract_all_category_data(invalid_category_link)\n",
    "        assert mock_extract_category_data.call_count == 1\n",
    "        mock_extract_category_data.assert_any_call(\n",
    "            {'link': 'invalid-url'}, False\n",
    "        )\n",
    "\n",
    "def test_extract_all_category_data_category_with_missing_link(\n",
    "    category_with_missing_link\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_all_category_data` handles category with missing link.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch('__main__.extract_category_data') as mock_extract_category_data\n",
    "    ):\n",
    "        extract_all_category_data(category_with_missing_link)\n",
    "        assert mock_extract_category_data.call_count == 1\n",
    "        mock_extract_category_data.assert_any_call(\n",
    "            {}, False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_book_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `extract_book_data`\n",
    "import pytest\n",
    "from bs4 import BeautifulSoup\n",
    "from unittest.mock import patch\n",
    "\n",
    "@pytest.fixture\n",
    "def category_page():\n",
    "    return BeautifulSoup(CATEGORY_HTML_VALID, HTML_PARSER)\n",
    "\n",
    "BOOK_DATA_FOR_TEST = [\n",
    "    TEST_BOOK_DATA[0], \n",
    "    TEST_BOOK_DATA[1],\n",
    "    TEST_BOOK_DATA[2]\n",
    "]\n",
    "\n",
    "def test_extract_book_data_single_page(category_page):\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data` correctly extracts book data from a single page.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[BOOK_DATA_FOR_TEST[0]]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_book_data(\n",
    "            category_page,\n",
    "            list(TEST_CATEGORIES_WITH_LINKS[0].values())[0]\n",
    "        )\n",
    "        assert len(books) == 1\n",
    "        assert books == [BOOK_DATA_FOR_TEST[0]]\n",
    "\n",
    "def test_extract_book_data_no_books(category_page):\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data` returns an empty list when no books are found.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_book_data(\n",
    "            category_page,\n",
    "            list(TEST_CATEGORIES_WITH_LINKS[0].values())[0]\n",
    "        )\n",
    "        assert len(books) == 0\n",
    "        assert books == []\n",
    "\n",
    "def test_extract_book_data_invalid_data(category_page):\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data` correctly handles invalid data and returns the valid data.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[BOOK_DATA_FOR_TEST[0]]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_book_data(\n",
    "            category_page,\n",
    "            list(TEST_CATEGORIES_WITH_LINKS[0].values())[0]\n",
    "        )\n",
    "        assert len(books) == 1\n",
    "        assert books == [BOOK_DATA_FOR_TEST[0]]\n",
    "\n",
    "\"\"\"\n",
    "TESTS FOR MULTIPLE PAGES\n",
    "\"\"\"\n",
    "\n",
    "# Helper to make many books for testing\n",
    "def book_data_generator():\n",
    "    i = 2\n",
    "    while True:\n",
    "        yield [{'title': f'Book {i}', 'price': round(float(i), 2)}]\n",
    "        i += 1\n",
    "\n",
    "def test_extract_book_data_multiple_pages(category_page):\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data` correctly extracts book data from multiple pages.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_number_of_book_pages',\n",
    "            return_value=3\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[BOOK_DATA_FOR_TEST[0]]\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_additional_page_book_data',\n",
    "            side_effect=[[BOOK_DATA_FOR_TEST[1]], [BOOK_DATA_FOR_TEST[2]]]\n",
    "        ) as mock_extract_additional_page_book_data\n",
    "    ):\n",
    "        books = extract_book_data(\n",
    "            category_page,\n",
    "            list(TEST_CATEGORIES_WITH_LINKS[0].values())[0]\n",
    "        )\n",
    "        assert mock_extract_additional_page_book_data.call_count == 2\n",
    "        assert len(books) == len(BOOK_DATA_FOR_TEST)\n",
    "        assert books == BOOK_DATA_FOR_TEST\n",
    "        mock_extract_additional_page_book_data.assert_called()\n",
    "\n",
    "def test_extract_book_data_max_pages(category_page):\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data` correctly extracts book data from the maximum number of pages.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_number_of_book_pages',\n",
    "            return_value=100\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[BOOK_DATA_FOR_TEST[0]]\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_additional_page_book_data',\n",
    "            side_effect=book_data_generator()\n",
    "        )\n",
    "    ):\n",
    "        books = extract_book_data(\n",
    "            category_page,\n",
    "            list(TEST_CATEGORIES_WITH_LINKS[0].values())[0]\n",
    "        )\n",
    "        assert len(books) == 100\n",
    "        assert books[0] == BOOK_DATA_FOR_TEST[0]\n",
    "        assert books[-1] == {'title': 'Book 100', 'price': 100.00}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_book_data_from_page`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `extract_book_data_from_page`\n",
    "from bs4 import BeautifulSoup\n",
    "from unittest.mock import patch\n",
    "\n",
    "def test_extract_book_data_from_page_normal_case():\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data_from_page` correctly extracts book data from a page with multiple books.\n",
    "    \"\"\"  # noqa: E501\n",
    "    page = BeautifulSoup(BOOK_DATA_HTML_VALID, HTML_PARSER)\n",
    "\n",
    "    with patch(\n",
    "        '__main__.extract_book_data_from_article',\n",
    "        side_effect=[\n",
    "            TEST_BOOK_DATA[0],\n",
    "            TEST_BOOK_DATA[1]\n",
    "        ]\n",
    "    ):\n",
    "        books = extract_book_data_from_page(page)\n",
    "        assert len(books) == 2\n",
    "        assert books == [\n",
    "            TEST_BOOK_DATA[0],\n",
    "            TEST_BOOK_DATA[1]\n",
    "        ]\n",
    "\n",
    "def test_extract_book_data_from_page_no_books():\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data_from_page` returns an empty list when no books are found on the page.\n",
    "    \"\"\"  # noqa: E501\n",
    "    page = BeautifulSoup(TEST_HTML, HTML_PARSER)\n",
    "    books = extract_book_data_from_page(page)\n",
    "    assert len(books) == 0\n",
    "    assert books == []\n",
    "\n",
    "def test_extract_book_data_from_page_empty_page():\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data_from_page` returns an empty list when the page is empty.\n",
    "    \"\"\"  # noqa: E501\n",
    "    page = BeautifulSoup('', HTML_PARSER)\n",
    "    books = extract_book_data_from_page(page)\n",
    "    assert len(books) == 0\n",
    "    assert books == []\n",
    "\n",
    "def test_extract_book_data_from_page_invalid_data():\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data_from_page` correctly handles invalid book data and returns the valid data.\n",
    "    \"\"\"  # noqa: E501\n",
    "    page = BeautifulSoup(BOOK_DATA_HTML_INVALID, HTML_PARSER)\n",
    "\n",
    "    with patch(\n",
    "        '__main__.extract_book_data_from_article',\n",
    "        return_value=TEST_BOOK_DATA[3]\n",
    "    ):\n",
    "        books = extract_book_data_from_page(page)\n",
    "        assert len(books) == 1\n",
    "        assert books == [TEST_BOOK_DATA[3]]\n",
    "\n",
    "def test_extract_book_data_from_page_none_case():\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data_from_page` returns an empty list when the page is None.\n",
    "    \"\"\"  # noqa: E501\n",
    "    page = None\n",
    "\n",
    "    with patch(\n",
    "        '__main__.extract_book_data_from_article',\n",
    "        return_value=None\n",
    "    ):\n",
    "        books = extract_book_data_from_page(page)\n",
    "        assert len(books) == 0\n",
    "        assert books == []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_book_data_from_article`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `extract_book_data_from_article`\n",
    "from bs4 import BeautifulSoup\n",
    "from unittest.mock import patch\n",
    "\n",
    "def test_extract_book_data_from_article_normal_case():\n",
    "    \"\"\"\n",
    "        Verify `extract_book_data_from_article` correctly extracts book data from an article with valid data.\n",
    "    \"\"\"  # noqa: E501\n",
    "    article = BeautifulSoup(BOOK_DATA_HTML_VALID, HTML_PARSER)\n",
    "    with patch(\n",
    "        '__main__.extract_element',\n",
    "        side_effect=[\n",
    "            BeautifulSoup(SINGLE_BOOK_TITLE_HTML_VALID, HTML_PARSER),\n",
    "            BeautifulSoup(SINGLE_BOOK_PRICE_HTML_VALID, HTML_PARSER),\n",
    "        ]\n",
    "    ):\n",
    "        book = extract_book_data_from_article(article)\n",
    "        assert book == TEST_BOOK_DATA[0]\n",
    "\n",
    "def test_extract_book_data_from_article_truncated_title():\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data_from_article` correctly extracts book data from an article with a truncated title.\n",
    "    \"\"\"  # noqa: E501\n",
    "    article = BeautifulSoup(BOOK_DATA_HTML_TRUNCATED_TITLE, HTML_PARSER)\n",
    "    with patch(\n",
    "        '__main__.extract_element',\n",
    "        side_effect=[\n",
    "            BeautifulSoup(\n",
    "                SINGLE_BOOK_TITLE_HTML_TRUNCATED,\n",
    "                HTML_PARSER\n",
    "            ),\n",
    "            BeautifulSoup(\n",
    "                SINGLE_BOOK_TITLE_TRUN_PRICE_HTML_VALID,\n",
    "                HTML_PARSER\n",
    "            ),\n",
    "        ]\n",
    "    ):\n",
    "        book = extract_book_data_from_article(article)\n",
    "        assert book == TEST_BOOK_DATA[8]\n",
    "\n",
    "def test_extract_book_data_from_article_invalid_price():\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data_from_article` returns the price str when the price is invalid.\n",
    "    \"\"\"  # noqa: E501\n",
    "    article = BeautifulSoup(BOOK_DATA_HTML_INVALID, HTML_PARSER)\n",
    "    with patch(\n",
    "        '__main__.extract_element',\n",
    "        side_effect=[\n",
    "            BeautifulSoup(SINGLE_BOOK_TITLE_HTML_VALID, HTML_PARSER),\n",
    "            BeautifulSoup(SINGLE_BOOK_PRICE_HTML_INVALID, HTML_PARSER),\n",
    "        ]\n",
    "    ):\n",
    "        book = extract_book_data_from_article(article)\n",
    "        assert book == {\n",
    "            'title': TEST_BOOK_DATA[0]['title'],\n",
    "            'price': TEST_BOOK_DATA[3]['price']\n",
    "        }\n",
    "\n",
    "def test_extract_book_data_from_article_missing_price():\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data_from_article` returns None for price when element is missing from the article.\n",
    "    \"\"\"  # noqa: E501\n",
    "    article = BeautifulSoup(BOOK_DATA_HTML_MISSING_PRICE, HTML_PARSER)\n",
    "    with patch(\n",
    "        '__main__.extract_element',\n",
    "        side_effect=[\n",
    "            BeautifulSoup(SINGLE_BOOK_TITLE_HTML_VALID, HTML_PARSER),\n",
    "            None\n",
    "        ]\n",
    "    ):\n",
    "        book = extract_book_data_from_article(article)\n",
    "        assert book == {\n",
    "            'title': TEST_BOOK_DATA[0]['title'],\n",
    "            'price': None\n",
    "        }\n",
    "\n",
    "def test_extract_book_data_from_article_missing_title_attribute():\n",
    "    \"\"\"\n",
    "    Verify `extract_book_data_from_article` returns None for the title when attribute is missing.\n",
    "    \"\"\"  # noqa: E501\n",
    "    article = BeautifulSoup(BOOK_DATA_HTML_NO_TITLE_ATTR, HTML_PARSER)\n",
    "    with patch(\n",
    "        '__main__.extract_element',\n",
    "        side_effect=[\n",
    "            BeautifulSoup(SINGLE_BOOK_TITLE_HTML_NO_ATTR, HTML_PARSER),\n",
    "            BeautifulSoup(SINGLE_BOOK_PRICE_HTML_VALID, HTML_PARSER),\n",
    "        ]\n",
    "    ):\n",
    "        book = extract_book_data_from_article(article)\n",
    "        assert book == {\n",
    "            'title': None,\n",
    "            'price': TEST_BOOK_DATA[0]['price']\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_extract_number_of_book_pages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `extract_extract_number_of_book_pages`\n",
    "import pytest\n",
    "from unittest.mock import patch\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "@pytest.fixture\n",
    "def category_page():\n",
    "    return BeautifulSoup(CATEGORY_HTML_VALID, 'html.parser')\n",
    "\n",
    "def test_extract_number_of_book_pages_pagination_not_found(\n",
    "    category_page\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_number_of_book_pages` returns 1 when no pagination is found.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with patch('__main__.extract_element', return_value=None):\n",
    "        assert extract_number_of_book_pages(category_page) == 1\n",
    "\n",
    "def test_extract_number_of_book_pages_pagination_found_valid_text(\n",
    "    category_page\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_number_of_book_pages` correctly extracts the number of pages from valid pagination text.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_element',\n",
    "            return_value=BeautifulSoup(PAGINATION_VALID, 'html.parser').li\n",
    "        )\n",
    "    ):\n",
    "        assert extract_number_of_book_pages(category_page) == 4\n",
    "\n",
    "def test_extract_number_of_book_pages_pagination_found_invalid_text(\n",
    "    category_page\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_number_of_book_pages` returns 1 when the pagination text is invalid.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_element',\n",
    "            return_value=BeautifulSoup(PAGINATION_INVALID, 'html.parser').li\n",
    "        )\n",
    "    ):\n",
    "        assert extract_number_of_book_pages(category_page) == 1\n",
    "\n",
    "def test_extract_number_of_book_pages_pagination_edge_case_page_400(\n",
    "    category_page\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_number_of_book_pages` correctly extracts the number of pages from edge case pagination text 'Page 1 of 400'.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_element',\n",
    "            return_value=BeautifulSoup(PAGINATION_EDGE_400, 'html.parser').li\n",
    "        )\n",
    "    ):\n",
    "        assert extract_number_of_book_pages(category_page) == 400\n",
    "\n",
    "def test_extract_number_of_book_pages_pagination_edge_case_page_40(\n",
    "    category_page\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_number_of_book_pages` correctly extracts the number of pages from edge case pagination text 'Page 1 of 40'.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_element',\n",
    "            return_value=BeautifulSoup(PAGINATION_EDGE_40, 'html.parser').li\n",
    "        )\n",
    "    ):\n",
    "        assert extract_number_of_book_pages(category_page) == 40\n",
    "\n",
    "def test_extract_number_of_book_pages_pagination_edge_case_page_4(\n",
    "    category_page\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_number_of_book_pages` correctly extracts the number of pages from edge case pagination text 'Page 1 of 4'.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.extract_element',\n",
    "            return_value=BeautifulSoup(PAGINATION_EDGE_4, 'html.parser').li\n",
    "        )\n",
    "    ):\n",
    "        assert extract_number_of_book_pages(category_page) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_additional_page_book_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `extract_additional_page_book_data`\n",
    "import pytest\n",
    "from bs4 import BeautifulSoup\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Book data for testing\n",
    "BOOK_DATA_FOR_TESTS = [\n",
    "    TEST_BOOK_DATA[0],\n",
    "    TEST_BOOK_DATA[1]\n",
    "]\n",
    "\n",
    "@pytest.fixture\n",
    "def category_link():\n",
    "    return f\"{TEST_URL}/category1.html\"\n",
    "\n",
    "@pytest.fixture\n",
    "def book_data_html_valid_data_dict():\n",
    "    return {'data': BOOK_DATA_HTML_VALID}\n",
    "\n",
    "@pytest.fixture\n",
    "def empty_page_data_dict():\n",
    "    return {'data': TEST_HTML}\n",
    "\n",
    "@pytest.fixture\n",
    "def invalid_url_page_data():\n",
    "    return {'data': ''}\n",
    "\n",
    "@pytest.fixture\n",
    "def book_data_html_missing_price_data_dict():\n",
    "    return {'data': BOOK_DATA_HTML_MISSING_PRICE}\n",
    "\n",
    "@pytest.fixture\n",
    "def book_data_html_missing_title_data_dict():\n",
    "    return {'data': BOOK_DATA_HTML_MISSING_TITLE}\n",
    "\n",
    "@pytest.fixture\n",
    "def book_data_html_mixed_data_dict():\n",
    "    return {'data': BOOK_DATA_HTML_MIXED}\n",
    "\n",
    "def test_extract_additional_page_book_data_normal_case(\n",
    "    category_link,\n",
    "    book_data_html_valid_data_dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_additional_page_book_data` correctly extracts book data from a page with multiple books.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value=book_data_html_valid_data_dict\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            side_effect=[[BOOK_DATA_FOR_TESTS[0], BOOK_DATA_FOR_TESTS[1]]]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_additional_page_book_data(category_link, 2)\n",
    "        assert len(books) == 2\n",
    "        assert books == [BOOK_DATA_FOR_TESTS[0], BOOK_DATA_FOR_TESTS[1]]\n",
    "\n",
    "def test_extract_additional_page_book_data_invalid_url(\n",
    "    category_link,\n",
    "    invalid_url_page_data\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_additional_page_book_data` returns an empty list when the URL is invalid.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value=invalid_url_page_data\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_additional_page_book_data(category_link, 2)\n",
    "        assert len(books) == 0\n",
    "        assert books == []\n",
    "\n",
    "def test_extract_additional_page_book_data_empty_page(\n",
    "    category_link,\n",
    "    empty_page_data_dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_additional_page_book_data` returns an empty list when the page is empty.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value=empty_page_data_dict\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_additional_page_book_data(category_link, 2)\n",
    "        assert len(books) == 0\n",
    "        assert books == []\n",
    "\n",
    "def test_extract_additional_page_book_data_no_books(\n",
    "    category_link,\n",
    "    empty_page_data_dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_additional_page_book_data` returns an empty list when no books are found on the page.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value=empty_page_data_dict\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_additional_page_book_data(category_link, 2)\n",
    "        assert len(books) == 0\n",
    "        assert books == []\n",
    "\n",
    "def test_extract_additional_page_book_data_request_failure(\n",
    "    category_link\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_additional_page_book_data` returns an empty list when the request to scrape the page fails.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            side_effect=Exception('Request failed')\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_additional_page_book_data(category_link, 2)\n",
    "        assert len(books) == 0\n",
    "        assert books == []\n",
    "\n",
    "def test_extract_additional_page_book_data_missing_price(\n",
    "    category_link,\n",
    "    book_data_html_missing_price_data_dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_additional_page_book_data` correctly handles book data with missing price.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value=book_data_html_missing_price_data_dict\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[TEST_BOOK_DATA[4]]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_additional_page_book_data(category_link, 2)\n",
    "        assert len(books) == 1\n",
    "        assert books == [TEST_BOOK_DATA[4]]\n",
    "\n",
    "def test_extract_additional_page_book_data_missing_title(\n",
    "    category_link,\n",
    "    book_data_html_missing_title_data_dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_additional_page_book_data` correctly handles book data with missing title.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value=book_data_html_missing_title_data_dict\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[TEST_BOOK_DATA[4]]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_additional_page_book_data(category_link, 2)\n",
    "        assert len(books) == 1\n",
    "        assert books == [TEST_BOOK_DATA[4]]\n",
    "\n",
    "def test_extract_additional_page_book_data_mixed_data(\n",
    "    category_link,\n",
    "    book_data_html_mixed_data_dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify `extract_additional_page_book_data` correctly handles mixed valid and invalid book data.\n",
    "    \"\"\"   # noqa: E501\n",
    "    with (\n",
    "        patch(\n",
    "            '__main__.request_to_scrape',\n",
    "            return_value=book_data_html_mixed_data_dict\n",
    "        ),\n",
    "        patch(\n",
    "            '__main__.extract_book_data_from_page',\n",
    "            return_value=[\n",
    "                TEST_BOOK_DATA[0],\n",
    "                TEST_BOOK_DATA[4],\n",
    "                TEST_BOOK_DATA[5],\n",
    "                TEST_BOOK_DATA[7]\n",
    "            ]\n",
    "        )\n",
    "    ):\n",
    "        books = extract_additional_page_book_data(category_link, 2)\n",
    "        assert len(books) == 4\n",
    "        assert books == [\n",
    "            TEST_BOOK_DATA[0],\n",
    "            TEST_BOOK_DATA[4],\n",
    "            TEST_BOOK_DATA[5],\n",
    "            TEST_BOOK_DATA[7]  \n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the tests\n",
    "\n",
    "Run the cell containing the `ipytest.run()` command to execute the tests.  The tests should all fail until you have written the production code.\n",
    "\n",
    "Don't forget to run the installation and initialisation cell too on the first time you run the tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Python Production Code\n",
    "\n",
    "\n",
    "Develop any functions for use as production code in separate cells below. The first has been provided as an example under the Production Constants, add others as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRODUCTION CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRODUCTION CONSTANTS\n",
    "\n",
    "# Constants for status messages\n",
    "STATUS_SUCCESS = \"success\"\n",
    "STATUS_ERROR = \"error\"\n",
    "ERROR_NOT_HTML = \"The response is not HTML\"\n",
    "ERROR_REQUEST_FAILED = \"Request failed for URL\"\n",
    "ERROR_UNEXPECTED = \"Unexpected error for URL\"\n",
    "\n",
    "# HTML Parser\n",
    "HTML_PARSER = \"html.parser\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `request_to_scrape` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request_to_scrape Production Code\n",
    "import requests\n",
    "from requests.exceptions import RequestException, Timeout\n",
    "\n",
    "def request_to_scrape(url: str, timeout: int = 10) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an HTTP GET request to the specified URL and returns the response content.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL to which the GET request is sent.\n",
    "        timeout (int, optional): The timeout for the request in seconds. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing the status, data, and any error messages.\n",
    "                        - If the request is successful and returns HTML, 'status' is 'success' and 'data' contains the response text.\n",
    "                        - If the request fails or does not return HTML, 'status' is 'error' and 'error' contains the error message.\n",
    "    \"\"\"  # noqa: E501\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        # Raise an HTTPError for bad responses\n",
    "        response.raise_for_status()\n",
    "        # Check if the response contains HTML\n",
    "        if 'text/html' in response.headers.get('Content-Type', ''):\n",
    "            return {\n",
    "                \"status\": STATUS_SUCCESS,\n",
    "                \"data\": response.text\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": STATUS_ERROR,\n",
    "                \"error\": ERROR_NOT_HTML\n",
    "            }\n",
    "    except (Timeout, RequestException) as e:\n",
    "        return {\n",
    "            \"status\": STATUS_ERROR,\n",
    "            \"error\": f\"{str(e)} - {ERROR_REQUEST_FAILED}\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": f\"{str(e)} - {ERROR_UNEXPECTED}\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_book_categories` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `extract_book_categories` Production Code\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_book_categories(html: str, site: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts book categories and their corresponding links from the provided HTML content.\n",
    "    Args:\n",
    "        html (str): The HTML content of the webpage to parse.\n",
    "        site (str): The URL of the site from which the HTML content was retrieved.\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are category names and the values dictionaries containing the corresponding links.\n",
    "    \"\"\"  # noqa: E501\n",
    "    soup = BeautifulSoup(html, HTML_PARSER)\n",
    "    nav_list = extract_element(soup, 'ul', 'nav nav-list')\n",
    "    if nav_list is None:\n",
    "        return {}\n",
    "    category_list = extract_element(nav_list, 'ul')\n",
    "    categories = extract_categories_and_links(category_list, site)\n",
    "    return categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_element` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_element Production Code\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_element(\n",
    "    soup: BeautifulSoup, tag: str, class_name: str = None\n",
    ") -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Extracts an HTML element from a BeautifulSoup object based on the specified tag and optional class name.\n",
    "    Args:\n",
    "        soup (BeautifulSoup): The BeautifulSoup object to search within.\n",
    "        tag (str): The HTML tag to search for.\n",
    "        class_name (str, optional): The class name to filter the search. Defaults to None.\n",
    "    Returns:\n",
    "        Tag or None: The first matching Tag object if found, otherwise None.\n",
    "    \"\"\"  # noqa: E501\n",
    "    if soup is None:\n",
    "        return None\n",
    "    return soup.find(tag, class_=class_name) if class_name else soup.find(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_categories_and_links` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `extract_categories_and_links` Production Code\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_categories_and_links(\n",
    "    category_list: BeautifulSoup, site: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extracts categories and their corresponding links from a given list of HTML anchor elements.\n",
    "    Args:\n",
    "        category_list (BeautifulSoup object): A BeautifulSoup object containing a list of HTML anchor elements.\n",
    "        site (str): The site URL to append to relative links.\n",
    "    Returns:\n",
    "        dictionary: A dictionary of dictionaries where the keys are category names (str) and the values are the corresponding href links (str) in a dictionary.\n",
    "        e.g.\n",
    "        {\n",
    "            'Category 1': {'link': 'https://www.example.com/category1.html'},\n",
    "            'Category 2': {'link': 'https://www.example.com/category2.html'}\n",
    "        }\n",
    "    \"\"\"  # noqa: E501\n",
    "    if not category_list:\n",
    "        return {}\n",
    "\n",
    "    categories = {}\n",
    "    for link in category_list.find_all('a'):\n",
    "        category_name = link.get_text(strip=True)\n",
    "        category_href = link.get('href')\n",
    "        categories[category_name] = {\n",
    "            'link': f\"{site}/{category_href}\" if category_href else None\n",
    "        }\n",
    "\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_category_data` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `extract_category_data` Production Code\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_category_data(\n",
    "    category: dict, \n",
    "    get_book_data: bool = False\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extracts the number of books in a category and optionally the book data.\n",
    "    Args:\n",
    "        category (dict): A dictionary containing the category name and link.\n",
    "        get_book_data (bool, optional): A flag to indicate whether to extract book data. Defaults to False.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the category name, link, and number of books.\n",
    "    \"\"\"  # noqa: E501\n",
    "    category_page = request_to_scrape(category['link'])\n",
    "    soup = BeautifulSoup(category_page['data'], HTML_PARSER)\n",
    "\n",
    "    number_of_books = extract_number_in_category(soup)\n",
    "    category['number_of_books'] = number_of_books if isinstance(\n",
    "        number_of_books, \n",
    "        int\n",
    "    ) else 0\n",
    "    if get_book_data:\n",
    "        category['books'] = extract_book_data(soup, category)\n",
    "\n",
    "    return category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_number_in_category` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_number_in_category Production Code\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_number_in_category(category_page: BeautifulSoup) -> int:\n",
    "    \"\"\"\n",
    "    Extracts the number of books in a category from the category page.\n",
    "    Args:\n",
    "        category_page (BeautifulSoup): The BeautifulSoup object of the category page.\n",
    "    Returns:\n",
    "        int: The number of books in the category.\n",
    "    \"\"\"  # noqa: E501\n",
    "    form = extract_element(category_page, 'form', 'form-horizontal')\n",
    "    try:\n",
    "        number_of_books = int(\n",
    "            extract_element(form, 'strong').get_text(strip=True)\n",
    "        )\n",
    "    except (AttributeError, ValueError):\n",
    "        number_of_books = 0\n",
    "    return number_of_books\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_all_category_data` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_all_category_data Production Code\n",
    "\n",
    "def extract_all_category_data(\n",
    "    categories: dict,\n",
    "    get_book_data: bool = False\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extracts data for all categories and updates the categories dictionary with the extracted data.\n",
    "\n",
    "    Args:\n",
    "        categories (Dict[str, Dict[str, Any]]): A dictionary where the keys are category names and the values are dictionaries containing category information.\n",
    "        get_book_data (bool, optional): A flag to indicate whether to extract book data. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated categories dictionary with extracted data.\n",
    "    \"\"\"  # noqa: E501\n",
    "    for category in categories.values():\n",
    "        category_data = extract_category_data(category, get_book_data)\n",
    "        category.update(category_data)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_book_data` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `extract_book_data` Production Code\n",
    "\n",
    "def extract_book_data(category_page: BeautifulSoup, category: dict) -> list:\n",
    "    \"\"\"\n",
    "    Extracts book data from a category page.\n",
    "    Args:\n",
    "        category_page (BeautifulSoup): The BeautifulSoup object of the category page.\n",
    "        category (dict): A dictionary containing the category name and link.\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing book data in a dictionary.\n",
    "    \"\"\"  # noqa: E501\n",
    "    books = []\n",
    "    number_of_pages = extract_number_of_book_pages(category_page)\n",
    "    books.extend(extract_book_data_from_page(category_page))\n",
    "    if number_of_pages > 1:\n",
    "        for page_number in range(2, number_of_pages + 1):\n",
    "            try:\n",
    "                books.extend(\n",
    "                    extract_additional_page_book_data(\n",
    "                        category['link'],\n",
    "                        page_number\n",
    "                    )\n",
    "                )\n",
    "            except Exception:\n",
    "                break\n",
    "    return books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_book_data_from_page` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_book_data_from_page Production Code\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_book_data_from_page(page: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    Extracts book data from a category page.\n",
    "    Args:\n",
    "        page (BeautifulSoup): The BeautifulSoup object of the category page.\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing book data.\n",
    "    \"\"\"  # noqa: E501\n",
    "    if page is None:\n",
    "        return []\n",
    "    book_articles = page.find_all(class_='product_pod')\n",
    "    books = [\n",
    "        extract_book_data_from_article(book_markup) \n",
    "        for book_markup in book_articles\n",
    "    ]\n",
    "    return books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_book_data_from_article` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_book_data_from_article Production Code\n",
    "\n",
    "def extract_book_data_from_article(article: BeautifulSoup) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts book data from an article element.\n",
    "    Args:\n",
    "        article (BeautifulSoup): The BeautifulSoup object of the article element.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the book title and price.\n",
    "    \"\"\"  # noqa: E501\n",
    "    try:\n",
    "        title_element = extract_element(article, 'h3')\n",
    "        title = (\n",
    "            title_element.a['title'] \n",
    "            if title_element and title_element.a \n",
    "            else None\n",
    "        )\n",
    "        # title = title_element.get('a').get('title')\n",
    "        price_element = extract_element(article, 'p', 'price_color')\n",
    "        price_str = price_element.get_text(strip=True)\n",
    "        price = float(price_str.replace('Â£', ''))\n",
    "\n",
    "        return {\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "        }\n",
    "    except ValueError:\n",
    "        return {\n",
    "            'title': title,\n",
    "            'price': price_str\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            'title': title or None,\n",
    "            'price': None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_number_of_book_pages` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_number_of_book_pages Production Code\n",
    "\n",
    "def extract_number_of_book_pages(category_page: BeautifulSoup) -> int:\n",
    "    \"\"\"\n",
    "    Extracts the number of pages of books in a category from the category page text \n",
    "    showing number of pages, or 1 if not found.\n",
    "    Args:\n",
    "        category_page (BeautifulSoup): The BeautifulSoup object of the category page.\n",
    "    Returns:\n",
    "        int: The number of pages of books in the category.\n",
    "    \"\"\"  # noqa: E501\n",
    "    pagination = extract_element(category_page, 'li', 'current')\n",
    "    if pagination is None:\n",
    "        return 1\n",
    "    pagination_text = pagination.get_text(strip=True)\n",
    "    try:\n",
    "        return int(pagination_text.split()[-1])\n",
    "    except ValueError:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_additional_page_book_data` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `extract_additional_page_book_data` Production Code\n",
    "\n",
    "def extract_additional_page_book_data(\n",
    "    category_link: str,\n",
    "    page_number: int\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Extracts additional book data from a specific page number in a category.\n",
    "    Args:\n",
    "        category_link (str): The link to the category page.\n",
    "        page_number (int): The page number to extract book data.\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing book data.\n",
    "    \"\"\"  # noqa: E501\n",
    "    page_url = category_link.replace('index.html', f\"page-{page_number}.html\")\n",
    "    try:\n",
    "        page_data = request_to_scrape(page_url)\n",
    "        page_soup = BeautifulSoup(page_data['data'], HTML_PARSER)\n",
    "        return extract_book_data_from_page(page_soup)\n",
    "    except Exception:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Python Execution Code\n",
    "\n",
    "Develop any code to call the developed functions below.  Add additional cells so you don't need to re-run all of the code when you develop further scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Execution Code 1\n",
    "\n",
    "# Get the site's homepage\n",
    "site = 'http://books.toscrape.com'\n",
    "home_page = request_to_scrape(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Execution Code 2\n",
    "\n",
    "# Extract book categories from the homepage\n",
    "categories = extract_book_categories(home_page['data'], site)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Execution Code 3\n",
    "\n",
    "# category_data = extract_category_data(categories['Travel'])\n",
    "\n",
    "# print(category_data)\n",
    "\n",
    "# Get just the categories and the number of books in the category\n",
    "\n",
    "# category_data = extract_all_category_data(categories)\n",
    "\n",
    "# for category, data in category_data.items():\n",
    "#     print(f\"Category: {category}\")\n",
    "#     for key, value in data.items():\n",
    "#         print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Execution Code 4\n",
    "\n",
    "# Get the book data as well as the number of books in each category\n",
    "category_data = extract_all_category_data(categories, True)\n",
    "\n",
    "for category, data in category_data.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    for key, value in data.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Execution Code 5\n",
    "import json\n",
    "with open('category_data.json', 'w') as file:\n",
    "    json.dump(category_data, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Test and Linting Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `pytest` scripts in a Jupyter Notebook cell, we need to install the `ipytest` package.  This package is NOT required for a pipeline and therefore it can be removed from the `requirements.txt` file before adding the production code to the pipeline.\n",
    "\n",
    "To run linting, we need to install 2 packages `nbqa` and `flake8`.  We will make sure that `flake8` is included in the `requirements.txt` file when constructing the pipeline so that we can lint as part of the pipeline tests.\n",
    "\n",
    "Run the following cell to install the `ipytest`, `nbqa` and `flake8` packages and a coverage package to help determine if all of your production code is executed during the tests!\n",
    "\n",
    "This cell only needs to be run once (or after restarting the notebook kernel) to set up the environment for testing and linting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install the `ipytest`, `nbqa` and `flake8` packages\n",
    "!pip install ipytest nbqa flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up `ipytest` to execute `pytest` scripts in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ipytest for Jupyter Notebook\n",
    "\n",
    "import ipytest\n",
    "ipytest.autoconfig(rewrite_asserts=True, magics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a *config* file for `flake8`\n",
    "\n",
    "Run this script to create a file in your project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create a config file and ignore some flake8 rules\n",
    "!echo \"[flake8]\" > .flake8\n",
    "!echo \"ignore = E402, W291, F811\" >> .flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the tests and linting in the Jupyter Notebook\n",
    "\n",
    "Run the following cell ***EVERY TIME*** you want to run the tests and linting that you have written in the *Python Tests* cell above.\n",
    "\n",
    ">**Note:**\n",
    ">\n",
    "> This entire section does not need to be part of any pipeline scripts.  \n",
    "> It is only required for the Jupyter Notebook environment during development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tests\n",
    "ipytest.run(\"-vv\", \"-ss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the linter\n",
    "\n",
    "Run this script each time you want to lint your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run the linter\n",
    "!nbqa flake8 --show-source --format=pylint webscraping.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
